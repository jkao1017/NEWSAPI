import pickle
import spacy
import collections
from spacy.tokenizer import Tokenizer
from newsapi import NewsApiClient
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from google.colab import drive


nlp_eng = spacy.load('en_core_web_lg')
newsapi = NewsApiClient (api_key='36f1e65141bf46c3b6043b7914c2a45d')

articles = newsapi.get_everything(q='coronavirus', language='en', from_param='2022-02-27', to='2022-03-26', sort_by='relevancy', page_size=100 )
drive.mount('drive')

#filename = 'articlesCOVID.pckl'
#pickle.dump(articles, open(filename, 'wb'))
#filename = 'articlesCOVID.pckl'
#loaded_model = pickle.load(open(filename, 'rb'))
#filepath = '/content/path/to/file/articlesCOVID.pckl'
#pickle.dump(loaded_model, open(filepath, 'wb'))

dados = []
results = []

for x in articles['articles']:
    title = x['title']
    date = x['publishedAt']
    description = x['description']
    content = x['content']
    dados.append({'title':title, 'date':date, 'desc':description, 'content':content})
    
df = pd.DataFrame(dados)
df = df.dropna()
df.head()
df.to_csv('/content/drive/My Drive/Colab Notebooks/covid19.csv')


def get_keywords_eng(x):
  result = []
  punctuation = [',','.','!','?']
  pos = ['NOUN','VERB','PROPN']
  doc = nlp_eng(x)
  for token in doc:
    if (token.text in nlp_eng.Defaults.stop_words or token.text in punctuation):
      continue
    if (token.pos_ in pos):
      result.append(token.text)
    return result

for content in df.content.values:
    results.append([('#' + x[0]) for x in collections.Counter(get_keywords_eng(content)).most_common(5)])
df['keywords'] = results

text = ''
for x in results:
  for y in x:
    text += ' ' + y
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="black", colormap = 'tab20c').generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
